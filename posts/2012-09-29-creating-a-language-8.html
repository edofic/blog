---
title: Making a programming language: Part 8 - going faster
---

<div style="text-align: right;"></div><a href="http://edofic.blogspot.com/2012/08/making-programming-language-part-1-how.html" target="_blank">Table of contents</a>, <a href="https://github.com/edofic/scrat-lang" target="_blank">Whole project on github</a><br /><br />First of all, I wrote some tests for scrat. That was a bit challenging to get started. How do you test a language? I decided to write a bunch of programs that exercise and combine different language features. And then stare into code until I was absolutely sure they are correct. That's the problem with implementing a new language, nobody can tell you if your code is correct but your software, but you don't even know if software is correct.<br />So I wrote some test programs and <a href="http://en.wikipedia.org/wiki/Parsing" rel="wikipedia" target="_blank" title="Parsing">parsed</a> and evaluated them in my mind to produce final result. And then I wrote a class using ScalaTest that generates tests by iterating over the array of these <a href="http://en.wikipedia.org/wiki/Tuple" rel="wikipedia" target="_blank" title="Tuple">tuples</a>. Quite cool, oh and I also included some descriptions into the tuples. So I get nice output. I pondered this idea quite some time ago but finally implemented it a bit after functions and objects.<br /><br />So now I can do crazy <a href="http://www.techopedia.com/definition/3865/refactoring" rel="techopedia" target="_blank" title="Refactoring">refactorings</a> while still maintaining the language - I trust my tests! But first of all, some benchmarks. I decided to measure execution time of parsing and evaluation on the <a href="https://raw.github.com/edofic/scrat-lang/master/run/llist.scrat" target="_blank">linked-list consturctor</a>. To my surprise, parsing was quite slow. It started on about 800ms and dropped down to     200ms after a few executions(first time <a href="http://en.wikipedia.org/wiki/Object_lifetime" rel="wikipedia" target="_blank" title="Object lifetime">object creation</a> and <a href="http://en.wikipedia.org/wiki/Just-in-time_compilation" rel="wikipedia" target="_blank" title="Just-in-time compilation">JIT</a> I suppose). 200ms for 67 <a href="http://en.wikipedia.org/wiki/Source_lines_of_code" rel="wikipedia" target="_blank" title="Source lines of code">lines of code</a>? That would mean about 3 seconds on a 1000 line file <b>IF</b> complexity is linear(which I later leard it isn't!). And that's 3 seconds on fifth run or so, first run(which is the only one when doing real stuff) would be 10 seconds +, unacceptable. (evaluation takes a few ms)<br /><h3>Research</h3><div>At first I just gave it some thought. Well it's a <b>recursive </b>descent parser, and from what I remember it back traces on failure. So efficiency has a lot to do with grammar structure. And it won't be linear because you have to do (usually) more back tracing when dealing with longer input.</div><div>Internets here I come. </div><div>My thoughts were confirmed. I found some guys on forums complaining over speed and then Mr. Odersky himself commented something like this(from memory): <br /><pre>Well the parsers in scala standard library are more like an example how to do recusive descent, functional style. They are perfectly usable for parsing command lines but not for long files. You should use a parser generator for that.  <br /></pre>I was bummed. The reason I didn't use a parser generator was this close integration that parser as a library could provide me. By the way implementation of <a href="http://en.wikipedia.org/wiki/Parsing" rel="wikipedia" target="_blank" title="Parsing">Parsers</a> is remarkably short, ~800 lines but most of them are comments. But it has quite some problems. A lot of object creation - every time a parsing function is invoked <b>many object are created. </b>Each parser is an object and each combinator is an object too. This in itself is not a big deal, but no <a href="http://en.wikipedia.org/wiki/Memoization" rel="wikipedia" target="_blank" title="Memoization">memoization</a> is performed, so it becomes a big deal. Now many objects are created on each try, so when backtracing you have to <a href="http://www.techopedia.com/definition/27271/automatic-memory-management-amm" rel="techopedia" target="_blank" title="Automatic Memory Management">GC</a> all these object and then recreate them. It's clean but it's no wonder it's slow.<br />Some time passed by and I accidentally found out about <a href="http://en.wikipedia.org/wiki/Parsing_expression_grammar" rel="wikipedia" target="_blank" title="Parsing expression grammar">Packrat Parsing</a>. <a href="http://scala-programming-language.1934581.n4.nabble.com/attachment/1956909/0/packrat_parsers.pdf" target="_blank">This paper</a> provides details but the gist of it is to use <a href="http://en.wikipedia.org/wiki/Lazy_evaluation" rel="wikipedia" target="_blank" title="Lazy evaluation">lazy evaluation</a> and memoization to reduce object creation and speed things up.<br /><h3>Conversion and results</h3></div><div>Conversion is dead easy. It's fully described in scala api documentation. Basically you mix in PackratParsers and change def <name>: Parser[<type>] = ... to lazy val <name>: PackratParser[<type>] = ... and that's it. Mixed in trait provides the necessary implicit conversions, lazy makes sure the creation is only done once and new implementation of parseAll does some clever parsing. Oh and you needn't convert all parsers, the paper says the optimal perfomance is achieved with the right mix of standard <a href="http://en.wikipedia.org/wiki/Recursive_descent_parser" rel="wikipedia" target="_blank" title="Recursive descent parser">recursive descent parsers</a> and packrat(packrat does include some overhead on specific grammars and inputs). But I just converted all and run the benchmark again. And behold...11ms. On the best run. More like 15 on average. But that's still more than a whole order of magnitude faster. And it should scale better. </type></name></type></name></div><div><br /></div><div><b>next: </b>don't know yet. I caught up with my implementation(finally!). I thinking about making functions stronger by relaxing the rules of invocation and doing some syntax sugar for lambdas. That and java interop. Or possibly compiling to bytecode. </div>